<h1 style="text-align:center"> Chapter 5: Security Assessment and Testing</h1>

# Vulnerability Management

Cybersecurity professionals are responsible for building, operating, and maintaining security controls to protect against threats. Performing regular assessments and testing is an important component of this, as is making sure the controls in place are effective.

Vulnerabilities in your systems are inevitable, and new vulnerabilities will arise on a regular basis. `Vulnerability management` programs play a crucial role in identifying, prioritizing, and remediating vulnerabilities in our environments. They use `vulnerability scanning` to detect new vulnerabilities and then implement a remediation workflow to address the highest-priority vulnerabilities.

## Identifying Scan Targets

An organization has to determine which systems will be covered by a vulnerability scan. Which get scanned can depend on a variety of questions, like:

- What is the data classification of the info stored?
- Is this system exposed to the internet?
- What services are offered by this system?
- Is the system a production, test, or development system?

Automated techniques may be used, such as scanning tools that search for network or connected devices (known or unknown). This builds a `asset inventory`. Asset inventory and `asset criticality` can help decide which systems should be included and their priorities.

## Determining Scan Frequency

Vulnerability scanninig tools allow for automated scheduling of scans (Nessus). These scans should be configured to provide automated alerting when vulnerabilities are found. How often a organization conducts scans can depend on:

- The organization's `risk appetite`, its willingness to tolerate risk within the environment.
- `Regulatory requirements` may dictate a minimum frequency.
- `Technical constraints` can limit frequency.
- `Business constraints` may limit frequency due to resource-intensive scans may interfere with high business activity.
- `Licensing limitiations` may curtail bandwidth consumed by the scanner or the number of scans that may be conducted simultaneously.

Begin small, and slowly expand the scope and frequency.

## Configuring Vulnerability Scans

Admins can customize the types of checks performed by the scanner such as providing credentials to access target servers, installling scannnig agents on target servers, and conduct scan from a variety of network perspectives.

### Scan Sensitivity Levels

This determines the types of checks that will be performed. Should be in line to meet objectives and to minimize disruption of the system. Usually everything starts with a template. Plug-ins each perform a check for a specific vulnerability, and can be configured. Some can be disbled to fasten the scan and to prevent false positives.

`Intrusive plug-ins` are those that can actually disrupt or damage a system. One way to work with this is to test a copy of the system in a test environment.

### Supplementing Network Scans

Firewalls, IPS, and other protocols may interfere with scan results when conducting a test over a network. Remote scans can be supplemented. A scanner can be provided with credentials that allow it to retrieve configuration information and then analyze it to determine issues. This is `credentialed scanning` or `server-bsed scanning`. This is supplemented with `agent-based scanning`, where admins install small software agents on each target server. These agents conduct scans of teh configuration, providing an inside-out vulnerability scan, then report information back to the vulnerability management platform for analysis and reporting.

### Scan Perspective

`Scan perspective` refers to conducting a scan from different locations on a netowrk to provide a different view into vulnerabilities. External scans are run from the Internet showing the view of a attacker outside a location. Internal scanns might run from a scanner on the corporate network, showing the view of a malicious insider. Agents located on the server show the most accurate view - the real state of the server and its vulnerabilities.

Firewalls, Network segmentation, IDS, and IPS all may affect scans.

## Scanner Maintenance

Vulnerability scanners should be maintained to ensure the scanning software and `vulnerability feeds` remain up to date.

### Scanner Software

Even vulnerability scanners can have security issues. Regular patching is important.

### Vulnerability Plug-in Feeds

Scanners should be configured to retrieve new plug-ins regularly (preferabiliy daily). The `Security Content Automation Protocol (SCAP)` is an effort to create a standardized approach for communicating security-related information. The standard includes:

- `Common Configuration Enumeration (CCE)` - Provides a standard nomenclature for discussing system configuration issues
- `Common Platform Enumeration (CPE)` - Provides a standard nomenclature for describing product names and versions
- `Common Vulnerabilities and Exposures (CVE)` - Provides a standard nomenclature for describing security-related software flaws
- `Common Vulnerability Scoring System (CVSS)` - Provides a standardized approach for measuring and describing the severity of security-related software flaws
- `Extensible Configuration Checklist Description Format (XCCDF)` - A language for specifying checklists and reporting checklist results
- `Open Vulnerability and Assessment Language (OVAL)` - A language for specifying low-level testing procedures used by checklists

## Vulnerability Scanning Tools

In a cyversecurity toolkit, you should have a network vulnerability scanner, a application scanner, and a web application scanner available for use.

### Infrastructure Vulnerability Scanning

Network scanners reach out to any device connected to the network and attempt to determine the type of device and its configuration, then launch targeted tests for vulnerabilities. Many orgs will deploy two different vulnerability scanners as a defense-in-depth control. Examples include:

- Nessus.
- Qualys vulnerability scanner (SaaS).
- Rapid7's Nexpose.
- OpenVAS, opensource.

### Application Testing

Application testing tools are commonly used as part of the software development process. This should be part of the dev process. Application testing occurs using three techniques:

1. `Static testing` - analyzing code without executing it. Points directly to vulnerabilities and often provides remediation suggestions.
2. `Dynamic testing`- executes code as part of the test, running all interfaces that the code exposes to the user with a variety of inputs, searching for vulnerabilities.
3. `Interactive testing` - combines static and dynamic testing, analyzing the source code while testers interact with the application through exposed interfaces.

### Web Application Scanning

Web application vulnerability scanners are specialized tools checking the security of web applications. These test for web-specific vulnerabilities (e.g. SQL injection, cross-site scripting (XSS), and cross-site request forgery (CSRF)). They send known malicious input sequences and fuzzing.

Ex. Nikto - open source, or Arachni - open source.

## Reviewing and Interpreting Scan Reports

Vulnerability scan reports provide detailed information about each vulnerability they find. It provides severity, description of the vulnerability, possible remediations, and additional references. It also may have a output section that shows details of what the scanner finds, which can be used to further interpret the issues.

### Understanding CVSS

The `Common Vulnerability Scoring System (CVSS)` is a standard for assessing the severity of security vulnerabilities. A new vulnerability is rated on eight different measures.

Example: `CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N`

---

I. The `Attack Vector Metric (AV)` describes how an attacker would exploit a vulnerability.

Physical (P) - .20 | Local (L) - .55 | Adjacent (A) - .62 | Network (N) - .85

---

II. The `Attack Complexity Metric (AC)` describes the difficulty of exploiting the vulnerability.

High (H) - .44 | Low (L) - .77

---

III. The `Privileges Required Metric (PR)` describes the type of account access needed.

High (H) - .27 (or .5 is scope is changed) | Low (L) - .62 (or .68 is scope is changed) | None (N) - .85

---

IV. The `User Interaction Metric (UI)` describes whether the attacker needs to involve another human in the attack.

None (N) - 0.85 | Required (R) - .62

---

V. The `Confidentiality Metric (C)` describes the type of information disclosure that might occur if attack is successful.

None (N) - 0.0 | Low (L) - .22 | High (H) - .56

VI. The `Integrity Metric (I)` describes the type of information alteration that might occur.

None (N) - 0.0 | Low (L) - .22 | High (H0 - .56)

VII. The `Availability Metric (A)` describes the type of disruption that might occur.

None (N) - 0.0 | Low (L) - .22 | High (H0 - .56)

VIII. The `Scope Metric (S)` decribes whether the vulnerability can affect system components beyond the scope of the vulnerability.

Unchanged (U) | Changed (C)

### Interpreting the CVSS Vector

The `CVSS vector` uses single-line format to convey ratings on all 8 metrics.

### Summarizing CVSS Scores

The `CVSS base score` is obtained through a calculation of the individual metrics. NIST offers a calculator for arriving at this score.

### Categorizing CVSS Base Scores **_ ON TEST _**

Risk categories can be used to summarize results as well:

0.0 - None

0.1 - 3.9 - Low

4.0 - 6.9 - Medium

7.0 - 8.9 - High

9.0 - 10.0 - Critical

## Confirmation of Scan Results

Cybersecurity analysts interpreting reports will often perform their own investigations for confirmation.

### False Positives

Scanners are not foolproof. A `false positive error` occurs when a scanner reports a vulnerability that does not exist. A `positive report` occurs when a scanner reports a vulnerability. This report may be accurate (a `true prositive` report) or inaccurate (a `false positive` report). When a scanner reports a vulnerability is not present, it is a `negative report`. The negative report similarly may be accurate (a `true negative` report) or inaccurate (a `false negative` report).

<h2 style="text-align:center"> ----------- IMPORTANT FOR TEST ----------- </div>

Focus on understanding the topics of false positives and false negatives. You must understand the types of errors that might occur in vulnerability reports and be prepared to identify them in scenarios on the exam.

<h2 style="text-align:center"> ----------- IMPORTANT FOR TEST ----------- </div>

Whether a vulnerability exists should be confirmed by the analyst.

### Reconciling Scan Results with Other Data Sources

Scans should not take place in a vacuum. Other sources of security information should also be used, such as:

- `Log reviews` from servers, apps, network devices, etc.
- `Security information and event management (SIEM)` systems that correlate log entries.
- `Configuration management systems` that provide info on the OS and other apps.

# Vulnerability Classification

## Patch Management

Running outdated versions of software is one of the most commonly found issues, mostly due to lack of resources. Therefore a `patch management program` is highly important.

## Legacy Platforms

Sooner or later, vendors will discontinue support for products.

## Weak Configurations

Weak configurations may be found via vulnerability scans. These vulnerabilities include:

- Use of default settings that pose a security risk (such as administrative setup pages that are meant to be disabled).
- Default credentials or unsecured accounts. Lack of strong authentication or use of default passwords.
- Open, unnecessary service ports.
- Open permissions allowing users access that violate the principles of least privilege.

## Error Messages

`Debug modes` can provide detailed information on the inner workings of a application or a server. Ensure debug mode is only used on internal development.

## Insecure protocols

Use of outdated / unsecure protocols such as `Telnet` or `FTP`. Solution is to switch to more secure protocols (`SSH` or `FTPS`).

## Weak Encryption

Use of weak encryption methods can lead to an attacker guessing the encryption algorithm.

# Penetration Testing

`Penetration Testing` tests an organization's security through the use of technical tools. Penetration testers only need to find a single vulnerability to exploit in order to achieve their goals. The term `hacker mindset` is the process of thinking like an adversary who might attack a system. Instead of thinking high level, you focus on finding a flaw in the existing security controls.

## Reasons for Penetration Testing

They provide visibility into the organizations security posture that is not available in another means.

## Benefits of Penetration Testing

First, penetration tests provides knowledge that cant be obtained elsewhere. The experience of the tester applies here. Secondly, if the attacker is successful, we have a blueprint for remediation. Finally, tests can provide essential, focused information on specific attack areas.

`Threat hunters` use a attacker mindset to search the organization's technology infrastructure for the artifacts of a successful attack. Threat hunting builds on the philosophy of `presumption of compromise`. This assumes that attackers have already successfully breached an organization and searches out the evidence of successful attacks.

## Penetration Test Types

There are 4 major categories of penetration testing.

1. `Physical penetration testing` - focuses on identifying and exploiting vulnerabilities in an organization's physical security controls. Includes breaking into buildings, bypassing access control systems, or compromising surveillance systems. The objective is assess physical security measures.
2. `Offensive penetration testing` - proactive approach; security professionals act as attackers. Used to simulate real-world cyberattacks and determine how well an organization can detect, respond to, and recover from attacks.
3. `Defensive penetration testing` - evaluating an organziation's ability to defend against cyberattacks. This involves assessing the effectiveness of security policies, procedures, and technologies in detecting and mitigating threats.
4. `Integrated penetration testing` - combines aspects of both offensive and defensive testing. Provides comprehensive assessment.

There 3 classifications for the amount of knowledge penetration testers have.

1. `Known environment` - tests performed with full knowledge of underlying technology, configurations, and settings that make up the target. This includes having credentials, IP addresses, etc. This does not provide a accurate view of what external attackers may see.
2. `Unknown environment` - replicates what an external attacker would encounter. Can be time-consuming. The quality and skillset of the penetration tester or team is important.
3. `Partially known environment` - blend both of the above.

## Rules of Engagement

`Rules of engagement` include the following considerations.

1. `Timeline` of the engagement and when testing can be conducted. Think of non-critical timeframes to minimize impact and outages.
2. `Locations, systems, applications and other potential targets` are included or excluded.
3. `Data handling requirements` for information gathered during the test. Think sensitive information found, etc.
4. What `behaviors` to expect from the target. Defensive behaviors may limit the value of the test.
5. What `resources` are committed to the test. Includes time commitments from the admins, devs, etc.
6. `Legal concerns` should be addressed, including review of the laws covering the target and remote locations.
7. When and how `communications` will occur. When will reports be sent?

`Permissions` need to be covered, usually with a signed agreement. A get-out-of-jail free card. Having a way for proplem handling and resolution is also important. In the event that something breaks or an outage occurs in the course of the tests. Both sides should know what could go wrong and how to communicate when something comes up.

## Reconnaissance

Penetration tests begin with the `Reconnaissance phase`. The attacker attempts to gather as much information as possible on the target organization. `Passive reconnaissance` seek to gather information without directly engaging the target. This includes `OSINT`, domain information lookups, web searches, etc. `Active reconnaissance` directly engage the target through port scanning, footprinting to ID the operating system and applications in use, and vulnerability scanning.

One common technique is to identify wireless networks through `war driving`, which uses high range antennas in an attempt to eavesdrop on wireless connections. Nowadays, can include use of drones or UAVs (`war flying`).

## Running the Test

There is a method to a test, and usually include the following phases:

1. `Initial access` - occurs when the attacker exploits a vulnerability and gains access to a network.
2. `Privilege escalation` - use hacking techniques to shift from initial access to more privileged access (root).
3. `Pivoting (lateral movement)` - use initial systems accessed to gain access to other systems on the target network.
4. `Persistence` - use of backdoors and other mechanisms that will allow them to regain access to a network - especially after a vulnerability is patched.

`Exploitation frameworks`, such as Metasploit, are often used.

## Cleaning Up

Testers conduct close-out activities that include presenting results to management and cleaning up the traces of their work. This includes removing any tools installed on systems as well as any persistance mechanisms put in place.

# Audits and Assessments

Audits and Assessments help verify that adequate security controls are functioning properly and are effective. The following should be considered when scheduling reviews:

## Security Tests

`Security tests` verify that a control is functioning properly. Tests include automated scans, tool-assisted penetration tests, and manual attempts to undermine security.

- Availability of security testing resources
- Criticality of the systems and applications protected by the tested controls
- Sensitivity of information contained on tested systems and applications
- Likelihood of a technical failure of the mechanism implementing the control
- Likelihood of a misconfiguration of the control that would jeopardize security
- Risk that the system will come under attack
- Rate of change of the control configuration
- Other changes in the technical environment that may affect the control performance
- Difficulty and time required to perform a control test
- Impact of the test on normal business operations

Many security testing programs begin on a haphazard basis, with security professionals simply pointing their fancy new tools at whatever systems they come across first. Experimentation with new tools is fine, but security testing programs should be carefully designed and include rigorous, routine testing of systems using a risk-prioritized approach.

Disclosure programs allow researchers share vulnerabilities securily with vendors. This includes bug bounty programs.

## Security Assessments

`Security Assessments` are comprehensive reviews of the security of a system, application, or other tested environment. A professional performs risk assessments to identify vulnerabilities in a tested environment. These include testing tools and manual penetration tests, but also include a review of the threat environment, current and future risks, and the value of the targed environment.

## Security Audits

`Security Audits` are similar to security assessments but must be performed by independent auditors. Audits are formal examinations performed with the purpose of demonstrating the eeffectiveness of controls to a third party. This provides a impartial, unbiased view of controls. An `attestation` is the primary outcome and it is a formal statement that the auditors have reviewed the controls and found that they are both adequate to meet the control objectives and working properly. There are 3 types of Audits:

1. `Internal Audits` - performed by internal audit staff for internal audiences. Often performed for assurance that the organization is meeting `compliance obligations`.
2. `External Audits` - performed by outside auditing firm. High degree of external validity because thereare no conflict of interests.
3. `Independent Third-Party Audits` - conducted by another organization, such as by a regulatory party. These are a subcategory of external audits - the difference is who is requesting the audit. For independent audits, the request comes from a regulator, customer, or outside entity. Often this will be aimed at organizations that provide services to other organizations.

Auditing Standards provides the description of control objectives that should be met. One such framework is `COBIT (Control Objectives for Information and related Technologies)`, which describes the common requirements that organizations should have in place surrounding their information systems.

# Vulnerability Life Cycle

Made up of 5 stages:

1. `Vulnerability Identification` - The organization becomes aware of a vulnerability via scans, penetration tests, reports, or results from audits.
2. `Vulnerability Analysis` - After identifying a vulnerability, a analysis of that report is performed. This includes confirming the vulnerability exists, prioritizing and categorizing the vulnerability using tools, and supplementing the external analysis of the vulnerability with specific details.
3. `Vulnerability Response and Remediation` - Should guide the organziation to identify the vulnerabilities that are most in need of remediation. They should respond by applying a patch or corrective measure, use network segmentation to isolate the system, implement compensating controls, purchase insurance to transfer financial risk, and grant exceptions as part of a formal risk acceptance strategy.
4. `Validation of Remediation` - Validate that the vulnerability is no longer present. Done by rescanning and verifying the vulnerability is no longer there. For serious vulnerabilities, an external audit may be needed.
5. `Reporting` - Communicating the findings, actions taken, and lessons learned to relevant stakeholders within the organizastion. This keeps stakeholders informed. Reporting may include summarizing vulnerabilities, providing details on the actions taken, highlighting trends, patters, or areas requiring further attention, and offering recommendations for improvements in the vulnerability management process.

# Summary

I. Good vulnerability response and remediation practices include patching, insurance, segmentation, compensating controls, exceptions and exemptions.

## 1. Vulnerabilities in Computing

- **Sources**:
  - Weak patch management.
  - Insecure configurations (e.g., open permissions, weak encryption, open ports).
- **Detection Issues**:
  - **False Positive**: Vulnerability reported but doesn’t exist.
  - **False Negative**: Vulnerability exists but isn’t reported.

## 2. Threat Hunting

- Assumes compromise and searches for indicators of attack.
- Uses advisories, bulletins, and threat intelligence feeds.
- Focuses on detecting access and attacker movement within networks.

## 3. Vulnerability Scans

- Probes systems for known issues (application, network, web testing).
- **Types**:
  - Credentialed vs. noncredentialed.
  - Intrusive vs. nonintrusive.
- Utilizes:
  - **CVE** (Common Vulnerabilities and Exposures).
  - **CVSS** (Common Vulnerability Scoring System) for consistency and prioritization.

## 4. Penetration Testing

- Simulates attackers to identify weaknesses.
- **Types**:
  - **Known Environment**: Full access to system info.
  - **Unknown Environment**: No prior system info.
  - **Partially Known**: Limited system info.
- **Steps**:
  1. Reconnaissance.
  2. Initial Access.
  3. Privilege Escalation.
  4. Lateral Movement.
  5. Persistence.
  6. Cleanup.

## 5. Bug Bounty Programs

- External professionals report vulnerabilities for financial rewards.
- Encourages ethical hacking and improves system security.

## 6. Security Audits

- Formal evaluations of security controls by internal or external auditors.
- Results in an attestation of the organization’s security effectiveness.

## 7. Vulnerability Life Cycle

- **Stages**:
  1. **Identification**: Scans, tests, bug reports.
  2. **Analysis**: Confirmation, prioritization via CVSS/CVE.
  3. **Response**: Patching, isolating, risk management.
  4. **Validation**: Ensures vulnerability is resolved.
  5. **Reporting**: Informs stakeholders, trends, recommendations.

a, d, c, d, a, b, a, a, b, a, a, c, d, c, c, c, c, a, c, d
c, d, c, c, a, b, c, a, b, a, a, c, d, c, b, c, c, b, b, c

- 7

https://georgeom.net/StegOnline/checklist
